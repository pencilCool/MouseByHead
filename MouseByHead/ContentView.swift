//
//  ContentView.swift
//  MouseByHead
//
//  Created by yuhua Tang on 2025/5/4.
//
import SwiftUI
import AVFoundation
import Vision

extension String {
    var localized: String {
        return NSLocalizedString(self, comment: "")
    }
}

struct ContentView: View {
    @State private var sensitivity: Double = 1
    @State private var selectedCameraIndex: Int = 0
    @State private var isScrollingEnabled: Bool = true
    @State private var showAccessibilityAlert: Bool = false
    @State private var alertMessage: String = ""
    
    @StateObject private var cameraManager = CameraManager()

    var body: some View {
        VStack {
            // æ‘„åƒå¤´é¢„è§ˆ
            CameraPreview(cameraManager: cameraManager)
               .frame(maxWidth: .infinity, maxHeight: .infinity)

            // çµæ•åº¦è®¾ç½®
            HStack {
                Text("çµæ•åº¦:".localized)
                Slider(value: $sensitivity, in: 1...10, step: 1)
                    .onChange(of: sensitivity) { newValue in
                        cameraManager.sensitivity = Int(newValue)
                    }
                Text("\(Int(sensitivity))")
            }
           .padding()

            // æ‘„åƒå¤´é€‰æ‹©
            Picker("é€‰æ‹©æ‘„åƒå¤´".localized, selection: $selectedCameraIndex) {
                ForEach(0..<cameraManager.availableCameras.count, id: \.self) { index in
                    Text(cameraManager.availableCameras[index].localizedName)
                        .tag(index)
                }
            }
           .pickerStyle(MenuPickerStyle())
           .onChange(of: selectedCameraIndex) { newIndex in
                cameraManager.selectCamera(at: newIndex)
            }
           .padding()
        }
       .onAppear {
            cameraManager.startSession()
            checkCameraAccess()
            checkAccessibilityPermission()
        }.alert(isPresented: $showAccessibilityAlert) {
            Alert(title: Text("æˆæƒç”³è¯·".localized), message: Text("æ§åˆ¶ç”µè„‘æˆæƒ".localized), dismissButton: .default(Text("ç¡®å®š".localized)) {
                NSWorkspace.shared.open(URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility")!)
            })
        }.onReceive(cameraManager.$isScrollingEnabled) { scrollAble in
                if scrollAble == true {
                    showAlert(message: "ğŸŸ¢å‘å³æ­ªå¤´ï¼Œå…è®¸è§¦å‘é¼ æ ‡æ»šåŠ¨äº‹ä»¶".localized)
                } else {
                    showAlert(message: "ğŸ”´å‘å·¦æ­ªå¤´ï¼Œç¦æ­¢è§¦å‘é¼ æ ‡æ»šåŠ¨äº‹ä»¶".localized)
                }
        }
       
    }
    
    private func checkAccessibilityPermission() {
         let options: NSDictionary = [kAXTrustedCheckOptionPrompt.takeRetainedValue() as NSString: false]
         let isTrusted = AXIsProcessTrustedWithOptions(options)
         if !isTrusted {
             showAccessibilityAlert = true
         }
     }
    
    private func checkCameraAccess() {
        let status = AVCaptureDevice.authorizationStatus(for: .video)

        switch status {
        case .notDetermined:
            // å°šæœªè¯·æ±‚æƒé™ï¼Œä½ éœ€è¦è¯·æ±‚
            requestCameraAccess()
        case .authorized:
            // ç”¨æˆ·å·²æˆæƒï¼Œä½ å¯ä»¥ä½¿ç”¨æ‘„åƒå¤´
            print("Camera access authorized.")
            // åœ¨è¿™é‡Œè¿›è¡Œæ‘„åƒå¤´ç›¸å…³çš„æ“ä½œ (ä¾‹å¦‚ï¼Œè®¾ç½® AVCaptureSession)
        case .denied, .restricted:
            // ç”¨æˆ·å·²æ‹’ç»æˆæƒï¼Œæˆ–è€…åº”ç”¨è¢«é™åˆ¶è®¿é—®ã€‚
            // ä½ åº”è¯¥å‘ç”¨æˆ·æ˜¾ç¤ºä¸€ä¸ªè§£é‡Šä¸ºä»€ä¹ˆéœ€è¦è®¿é—®æ‘„åƒå¤´çš„æ¶ˆæ¯ã€‚
            print("Camera access denied or restricted.")
//            showCameraAccessDeniedAlert()
            requestCameraAccess()
        @unknown default:
            // å¤„ç†æœªæ¥å¯èƒ½æ·»åŠ çš„æ–°çŠ¶æ€
            print("Unknown authorization status")
        }
    }
    
    func requestCameraAccess() {
        AVCaptureDevice.requestAccess(for: .video) { granted in
            DispatchQueue.main.async { // ç¡®ä¿åœ¨ä¸»çº¿ç¨‹ä¸Šæ›´æ–° UI
                if granted {
                    // ç”¨æˆ·æˆäºˆäº†æƒé™
                    print("Camera access granted")
                    // åœ¨è¿™é‡Œè¿›è¡Œæ‘„åƒå¤´ç›¸å…³çš„æ“ä½œ
                } else {
                    // ç”¨æˆ·æ‹’ç»äº†æƒé™
                    print("Camera access denied")
                    self.showCameraAccessDeniedAlert() //æ˜¾ç¤ºæç¤º
                }
            }
        }
    }
    
    func showCameraAccessDeniedAlert() {
        let alert = NSAlert()
        alert.messageText = "æˆæƒç”³è¯·".localized
        alert.informativeText = ""
//        alert.buttonTitle = "å¥½çš„"
        alert.addButton(withTitle: "ç¡®å®š".localized) // æ·»åŠ ä¸€ä¸ªæŒ‰é’®ï¼Œç›´æ¥æ‰“å¼€è®¾ç½®

        let result = alert.runModal()

         if result == .alertFirstButtonReturn {
            // æ‰“å¼€ç³»ç»Ÿåå¥½è®¾ç½®ä¸­çš„â€œå®‰å…¨æ€§ä¸éšç§â€
            NSWorkspace.shared.open(URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Camera")!)
        }
    }

    private func showAlert(message: String) {
        let alertWindow = NSWindow(contentRect: NSRect(x: 0, y: 0, width: 300, height: 100), styleMask: [.borderless], backing: .buffered, defer: false)
        alertWindow.backgroundColor = NSColor.black.withAlphaComponent(0.7)
        alertWindow.isOpaque = false
        alertWindow.hasShadow = true
        alertWindow.level = .floating
        alertWindow.collectionBehavior = [.canJoinAllSpaces, .fullScreenAuxiliary]

        let textView = NSTextView(frame: NSRect(x: 0, y: 0, width: 200, height: 80))
        textView.string = message
        textView.alignment = .center

        // å‚ç›´å±…ä¸­
        let textContainer = textView.textContainer
        textContainer?.lineFragmentPadding = 0 // ç§»é™¤é»˜è®¤çš„è¡Œç‰‡æ®µå¡«å……

        let font = NSFont.systemFont(ofSize: 20)
        let lineHeight = font.capHeight
        let availableHeight = textView.bounds.height
        let verticalInset = (availableHeight - lineHeight) / 2
        textView.textContainerInset = NSSize(width: 0, height: verticalInset)


        textView.textColor = .white
        textView.font = font
        textView.backgroundColor = .clear
        textView.isEditable = false
        textView.isSelectable = false
        textView.layer?.cornerRadius = 20
        textView.clipsToBounds = true
        alertWindow.contentView = textView

        // å±…ä¸­æ˜¾ç¤º
        let screenRect = NSScreen.main?.visibleFrame ?? NSRect.zero
        let windowRect = alertWindow.frame
        alertWindow.setFrameOrigin(NSPoint(x: (screenRect.width - windowRect.width) / 2, y: (screenRect.height - windowRect.height) / 2))

        alertWindow.makeKeyAndOrderFront(nil)


        // è‡ªåŠ¨æ¶ˆå¤±
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
            alertWindow.orderOut(nil)
        }
    }

}

class CameraManager: NSObject, ObservableObject, AVCaptureVideoDataOutputSampleBufferDelegate {
    @Published var availableCameras: [AVCaptureDevice] = []
    @Published var sensitivity: Int = 1
    @Published var isScrollingEnabled:Bool = true
    var captureSession: AVCaptureSession?
    var videoDataOutput: AVCaptureVideoDataOutput?
    var faceDetectionRequest: VNDetectFaceRectanglesRequest?
    var sequenceHandler = VNSequenceRequestHandler()
    
    let dataOutputQueue = DispatchQueue(
      label: "com.pencilcool.mousebyhead.video.data.queue",
      qos: .userInitiated,
      attributes: [],
      autoreleaseFrequency: .workItem)
    
    override init() {
        super.init()
        setupSession()
        setupFaceDetection()
    }

    func setupSession() {
        captureSession = AVCaptureSession()
        guard let session = captureSession else { return }
        
        let discoverySession = AVCaptureDevice.DiscoverySession(deviceTypes: [.builtInWideAngleCamera], mediaType: .video, position: .unspecified)
        availableCameras = discoverySession.devices
        
        if let firstDevice = availableCameras.first {
            setupInputDevice(firstDevice)
        }
        
        videoDataOutput = AVCaptureVideoDataOutput()
        videoDataOutput?.setSampleBufferDelegate(self, queue: dataOutputQueue)
        
        if session.canAddOutput(videoDataOutput!) {
            session.addOutput(videoDataOutput!)
        }
    }
    
    func setupInputDevice(_ device: AVCaptureDevice) {
        guard let session = captureSession else { return }
        if let currentInput = session.inputs.first as? AVCaptureDeviceInput {
            session.removeInput(currentInput)
        }
        if let newInput = try? AVCaptureDeviceInput(device: device) {
            if session.canAddInput(newInput) {
                session.addInput(newInput)
            }
        }
    }

    func startSession() {
        captureSession?.startRunning()
    }

    func selectCamera(at index: Int) {
        if index < availableCameras.count {
            setupInputDevice(availableCameras[index])
        }
    }

    func handleFaceObservation(observation: VNFaceObservation) {
//        let  yaw = observation.yaw?.doubleValue ?? 0
        let pitch = observation.pitch?.doubleValue ?? 0
        let roll = observation.roll?.doubleValue ?? 0
        if roll > 0.2  {
            // å³æ­ªå¤´
            isScrollingEnabled = true
            print("[pencilCool]  scrollAble")
        } else if roll < -0.2 {
            // å·¦æ­ªå¤´
            isScrollingEnabled = false
            print("[pencilCool]  not scrollAble")
        }
        
        if (isScrollingEnabled == false) {
           return
        }
//        print("roll:\(roll),yaw:\(yaw),pitch:\(pitch)")
        if pitch > 0.1 {
            // ä½å¤´
            print("[pencilCool]  down")
            scrollMouse(by: sensitivity)
        } else if pitch < -0.1 {
            // æŠ¬å¤´
            print("[pencilCool]  up")
            scrollMouse(by: -sensitivity)
        }
    }

    func scrollMouse(by delta: Int) {
        scrollMouse(xLines: delta, yLines: delta)
    }
   
    func scrollMouse(xLines: Int, yLines: Int) {
        guard let scrollEvent = CGEvent(scrollWheelEvent2Source: nil, units: CGScrollEventUnit.line, wheelCount: 2, wheel1: Int32(yLines), wheel2: Int32(xLines), wheel3: 0) else {
            return
        }
        scrollEvent.setIntegerValueField(CGEventField.eventSourceUserData, value: 1)

        // éœ€è¦è¾…åŠ©åŠŸèƒ½æƒé™
          let accessEnabled = AXIsProcessTrustedWithOptions(nil)
          if accessEnabled {
              scrollEvent.post(tap: CGEventTapLocation.cghidEventTap)
          } else {
              print("Accessibility access is not enabled. Please grant permission in System Settings > Privacy & Security > Accessibility.")
              // å¼•å¯¼ç”¨æˆ·å»å¼€å¯æƒé™
        //                  _ = CameraManager.onceAccessibility
          }



    }
    
    static let onceAccessibility: Void = {
        NSWorkspace.shared.open(URL(string: "x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility")!)
            return ()
        }()
 
    func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let faceDetectionRequest = faceDetectionRequest else { return }
        let imageRequestHandler = VNImageRequestHandler(cmSampleBuffer: sampleBuffer, orientation: .up, options: [:])
        do {
          try imageRequestHandler.perform([faceDetectionRequest])
        } catch {
          print("Error performing face detection request: \(error)")
        }
        
//        guard let imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
//          return
//        }
//        do {
//          try sequenceHandler.perform(
//            [faceDetectionRequest],
//            on: imageBuffer,
//            orientation: .up)
//        } catch {
//          print(error.localizedDescription)
//        }
    }
    
    
    func setupFaceDetection() {
        faceDetectionRequest = VNDetectFaceRectanglesRequest(completionHandler: { [weak self] (request, error) in
            guard let self = self else { return }
            if let error = error {
                print("Face detection error: \(error)")
                return
            }
            
            guard let observations = request.results as? [VNFaceObservation],
                  let firstObservation = observations.first else { return }
            
            self.handleFaceObservation(observation: firstObservation)
        })
    }
}

struct CameraPreview: NSViewRepresentable {
    let cameraManager: CameraManager

    func makeNSView(context: Context) -> NSView {
        let view = NSView()
        let videoLayer = AVCaptureVideoPreviewLayer(session: cameraManager.captureSession!)
        videoLayer.frame = view.bounds
        videoLayer.connection?.automaticallyAdjustsVideoMirroring = false;
        videoLayer.connection?.isVideoMirrored = true;
        view.layer = videoLayer
        view.wantsLayer = true
        return view
    }

    func updateNSView(_ nsView: NSView, context: Context) {
        if let videoLayer = nsView.layer as? AVCaptureVideoPreviewLayer {
            videoLayer.session = cameraManager.captureSession
        }
    }
}
   
